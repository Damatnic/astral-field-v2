# Quantum's AlertManager Deployment
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: astralfield-monitoring
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: monitoring
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_from: 'alerts@astralfield.com'
      smtp_auth_username: 'alerts@astralfield.com'
      smtp_auth_password: 'your-app-password'
      slack_api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'

    # Define templates
    templates:
      - '/etc/alertmanager/templates/*.tmpl'

    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
        group_wait: 10s
        repeat_interval: 5m
      - match:
          severity: warning
        receiver: 'warning-alerts'
        repeat_interval: 15m
      - match:
          team: database
        receiver: 'database-team'
      - match:
          team: platform
        receiver: 'platform-team'
      - match:
          service: live-events
        receiver: 'live-events-team'
        group_wait: 5s
        repeat_interval: 2m

    inhibit_rules:
      - source_match:
          severity: 'critical'
        target_match:
          severity: 'warning'
        equal: ['alertname', 'dev', 'instance']

    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://webhook-service:5000/alerts'
        send_resolved: true

    - name: 'critical-alerts'
      email_configs:
      - to: 'oncall@astralfield.com'
        subject: 'üö® CRITICAL: {{ .GroupLabels.alertname }} - {{ .GroupLabels.cluster }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Service: {{ .Labels.service }}
          Instance: {{ .Labels.instance }}
          Runbook: {{ .Annotations.runbook_url }}
          {{ end }}
      slack_configs:
      - channel: '#critical-alerts'
        title: 'üö® Critical Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Severity:* {{ .Labels.severity }}
          *Service:* {{ .Labels.service }}
          *Runbook:* {{ .Annotations.runbook_url }}
          {{ end }}
        send_resolved: true

    - name: 'warning-alerts'
      email_configs:
      - to: 'engineering@astralfield.com'
        subject: '‚ö†Ô∏è WARNING: {{ .GroupLabels.alertname }} - {{ .GroupLabels.cluster }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Severity: {{ .Labels.severity }}
          Service: {{ .Labels.service }}
          {{ end }}
      slack_configs:
      - channel: '#alerts'
        title: '‚ö†Ô∏è Warning: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Service:* {{ .Labels.service }}
          {{ end }}

    - name: 'database-team'
      email_configs:
      - to: 'database-team@astralfield.com'
        subject: 'üóÑÔ∏è Database Alert: {{ .GroupLabels.alertname }}'
      slack_configs:
      - channel: '#database-alerts'
        title: 'üóÑÔ∏è Database Alert: {{ .GroupLabels.alertname }}'

    - name: 'platform-team'
      email_configs:
      - to: 'platform-team@astralfield.com'
        subject: 'üèóÔ∏è Infrastructure Alert: {{ .GroupLabels.alertname }}'
      slack_configs:
      - channel: '#platform-alerts'
        title: 'üèóÔ∏è Infrastructure Alert: {{ .GroupLabels.alertname }}'

    - name: 'live-events-team'
      email_configs:
      - to: 'live-events@astralfield.com'
        subject: 'üèà Live Event Alert: {{ .GroupLabels.alertname }}'
      slack_configs:
      - channel: '#live-events'
        title: 'üèà Live Event Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Service:* {{ .Labels.service }}
          *Urgency:* High - Live sports event in progress
          {{ end }}

  alert-templates.tmpl: |
    {{ define "slack.title" }}
    [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.SortedPairs.Values | join " " }} {{ if gt (len .GroupLabels) 0 }}({{ .GroupLabels.SortedPairs.Names | join "/" }}){{ end }}
    {{ end }}

    {{ define "slack.text" }}
    {{ range .Alerts -}}
    *Alert:* {{ .Annotations.title }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}
    *Description:* {{ .Annotations.description }}
    *Details:*
      {{ range .Labels.SortedPairs }} ‚Ä¢ *{{ .Name }}:* `{{ .Value }}`
      {{ end }}
    {{ end }}
    {{ end }}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: astralfield-monitoring
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/component: monitoring
  template:
    metadata:
      labels:
        app.kubernetes.io/name: alertmanager
        app.kubernetes.io/component: monitoring
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        fsGroup: 65534
      containers:
      - name: alertmanager
        image: prom/alertmanager:v0.26.0
        args:
          - '--config.file=/etc/alertmanager/alertmanager.yml'
          - '--storage.path=/alertmanager'
          - '--data.retention=120h'
          - '--web.listen-address=:9093'
          - '--web.external-url=http://alertmanager.astralfield.com'
          - '--cluster.listen-address=0.0.0.0:9094'
          - '--cluster.peer=alertmanager-1.alertmanager:9094'
          - '--log.level=info'
        ports:
        - containerPort: 9093
          name: web
        - containerPort: 9094
          name: cluster
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        volumeMounts:
        - name: config-volume
          mountPath: /etc/alertmanager
        - name: alertmanager-storage
          mountPath: /alertmanager
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9093
          initialDelaySeconds: 30
          timeoutSeconds: 30
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9093
          initialDelaySeconds: 30
          timeoutSeconds: 30
      volumes:
      - name: config-volume
        configMap:
          name: alertmanager-config
      - name: alertmanager-storage
        emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: astralfield-monitoring
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: monitoring
spec:
  type: ClusterIP
  ports:
  - port: 9093
    targetPort: 9093
    protocol: TCP
    name: web
  - port: 9094
    targetPort: 9094
    protocol: TCP
    name: cluster
  selector:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: monitoring
---
# Headless service for AlertManager clustering
apiVersion: v1
kind: Service
metadata:
  name: alertmanager-headless
  namespace: astralfield-monitoring
  labels:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: monitoring
spec:
  clusterIP: None
  ports:
  - port: 9094
    targetPort: 9094
    protocol: TCP
    name: cluster
  selector:
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/component: monitoring